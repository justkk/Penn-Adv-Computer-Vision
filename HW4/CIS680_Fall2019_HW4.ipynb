{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS680_Fall2019_HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9qxR8EhmrSGW",
        "xkT0EMspKy64",
        "9X58DG3DrXx4",
        "51qcg1_Irjwf",
        "DJwXHWmErojM",
        "p5df0Zrfrs0J",
        "EvNh3B3FiAPY",
        "mSyobxVWqBMA"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHbNxdP6eLd2",
        "colab_type": "text"
      },
      "source": [
        "# Google Drive\n",
        "\n",
        "This first code block attaches your google drive and makes a folder structure. You only need to run this when a new VM is assigned to you. To get your code as a single python file go through the following menus File->'Download .py'.\n",
        "\n",
        "This also downloads the 2 files that contain the dataset and the checkpoint:\n",
        "\n",
        "\n",
        "https://drive.google.com/open?id=1ABUtpgdWMnMG6S6wLgqxXnAQ-8Fyq5F0\n",
        "\n",
        "https://drive.google.com/open?id=1ilx871Zws-rS1Ek_ZAC-imD50A8bTQ80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDRvN60UA_xm",
        "colab_type": "code",
        "outputId": "a9f67643-9d80-4f1e-ed74-bd825825a3a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYICcmTfdm0J",
        "colab_type": "code",
        "outputId": "5535d700-2e33-43fa-849c-e12afe231e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount google drive\n",
        "DRIVE_MOUNT='/content/gdrive'\n",
        "drive.mount(DRIVE_MOUNT)\n",
        "\n",
        "\n",
        "# create folder to write data to\n",
        "CIS680_FOLDER=os.path.join(DRIVE_MOUNT, 'My Drive', 'CIS680_2019')\n",
        "HOMEWORK_FOLDER=os.path.join(CIS680_FOLDER, 'HW3a')\n",
        "os.makedirs(HOMEWORK_FOLDER, exist_ok=True)\n",
        "\n",
        "# bootstrap environment into place\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "import io\n",
        "import os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "def download_file(fn, file_id):\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    downloaded = io.BytesIO()\n",
        "    downloader = MediaIoBaseDownload(downloaded, request)\n",
        "    done = False\n",
        "    while done is False:\n",
        "        # _ is a placeholder for a progress object that we ignore.\n",
        "        # (Our file is small, so we skip reporting progress.)\n",
        "        _, done = downloader.next_chunk()\n",
        "    \n",
        "    downloaded.seek(0)\n",
        "\n",
        "    folder = fn.split('/')\n",
        "    if len(folder) > 1:\n",
        "        os.makedirs(folder[0], exist_ok=True)\n",
        "\n",
        "    with open(fn, 'wb') as f:\n",
        "        f.write(downloaded.read())\n",
        "\n",
        "id_to_fn = {\n",
        "'1ABUtpgdWMnMG6S6wLgqxXnAQ-8Fyq5F0': 'test.npz',\n",
        "'1ilx871Zws-rS1Ek_ZAC-imD50A8bTQ80': 'train.npz',\n",
        "}\n",
        "\n",
        "# download all files into the vm\n",
        "for fid, fn in id_to_fn.items():\n",
        "    print(\"Downloading %s from %s\" % (fn, fid))\n",
        "    download_file(fn, fid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Downloading test.npz from 1ABUtpgdWMnMG6S6wLgqxXnAQ-8Fyq5F0\n",
            "Downloading train.npz from 1ilx871Zws-rS1Ek_ZAC-imD50A8bTQ80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfKoCTkHr3OX",
        "colab_type": "text"
      },
      "source": [
        "# Basic Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2NfwmoRr2c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "from skimage.transform import resize\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCWsblqPrOvq",
        "colab_type": "text"
      },
      "source": [
        "# 2.1 VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qxR8EhmrSGW",
        "colab_type": "text"
      },
      "source": [
        "## VAE Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4guVluChrR28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = datasets.MNIST('./files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor()\n",
        "                             ]))\n",
        "\n",
        "test_dataset = datasets.MNIST('./files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor()\n",
        "                             ]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkT0EMspKy64",
        "colab_type": "text"
      },
      "source": [
        "## VAE Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U1v81rTK3cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)\n",
        "\n",
        "test_recon_loader = DataLoader(test_dataset, batch_size=100, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X58DG3DrXx4",
        "colab_type": "text"
      },
      "source": [
        "## VAE Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXI5gLsordEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc1 = nn.Sequential(nn.Linear(784, 400), nn.ReLU())\n",
        "    self.fc2a = nn.Sequential(nn.Linear(400, 20), nn.ReLU())\n",
        "    self.fc2b = nn.Sequential(nn.Linear(400, 20), nn.ReLU())\n",
        "    \n",
        "    self.fc3 = nn.Sequential(nn.Linear(20, 400), nn.ReLU())\n",
        "    self.fc4 = nn.Sequential(nn.Linear(400, 784), nn.Sigmoid())\n",
        "  \n",
        "  def sample_z(self, mu, sigma):\n",
        "    z = torch.randn_like(mu) * sigma + mu\n",
        "    return z\n",
        "  \n",
        "  def encoder(self, X):\n",
        "    fc1_out = self.fc1(X)\n",
        "    mu = self.fc2a(fc1_out)\n",
        "    ln_var = self.fc2b(fc1_out)\n",
        "    return mu, ln_var.exp()\n",
        "  \n",
        "  def decoder(self, z):\n",
        "    fc3_out = self.fc3(z)\n",
        "    fc4_out = self.fc4(fc3_out)\n",
        "    return fc4_out\n",
        "    \n",
        "  def forward(self, X):\n",
        "    X = X.view(-1, 784)\n",
        "    mu, var = self.encoder(X)\n",
        "    sigma = torch.sqrt(var)\n",
        "    z = self.sample_z(mu, sigma)\n",
        "    decoder_out = self.decoder(z)\n",
        "    return mu, var, decoder_out\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usxT6vPErdln",
        "colab_type": "text"
      },
      "source": [
        "## VAE Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bZXBikcriZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(mu, var, decoder_out, x_input):\n",
        "  KLD = -0.5 * torch.sum( 1 + torch.log(var) - mu.pow(2) - var)\n",
        "  reconstruction_error = F.binary_cross_entropy(decoder_out, x_input, reduction='sum')\n",
        "  return reconstruction_error , KLD\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51qcg1_Irjwf",
        "colab_type": "text"
      },
      "source": [
        "## VAE Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiIp0N3drn4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAEWrapper():\n",
        "  def __init__(self, vae, lr):\n",
        "    self.vae = vae.to(device)\n",
        "    self.adam = torch.optim.Adam(self.vae.parameters())\n",
        "    self.train_loss_data, self.test_loss_data = [], []\n",
        "    self.infer_out = []\n",
        "  \n",
        "  def infer_data(self, X):\n",
        "    with torch.no_grad():\n",
        "      n_input = torch.tensor(X).type(torch.float).to(device)\n",
        "      mu, var, decoder_out = self.vae(n_input)\n",
        "      image_out = decoder_out.view(-1, 28, 28).cpu()\n",
        "      return image_out\n",
        "  \n",
        "  def infer_data_from_loader(self, data_loader):\n",
        "    main_out = []\n",
        "    with torch.no_grad():\n",
        "      for batch_id, (samples, labels) in enumerate(data_loader):\n",
        "        samples = samples.to(device)\n",
        "        _, _, output = self.vae(samples)\n",
        "        main_out.append(output.detach().cpu().view(-1, 28, 28))\n",
        "    return main_out\n",
        "\n",
        "    \n",
        "  def train_network(self, data_loader, epoch=0): \n",
        "    for batch_id, (samples, labels) in enumerate(data_loader):\n",
        "      self.adam.zero_grad()\n",
        "      samples_flat = samples.view(-1, 784).to(device)\n",
        "      mu, var, decoder_out = self.vae(samples_flat)\n",
        "      recon_loss, kld_loss = loss_function(mu, var, decoder_out, samples_flat)\n",
        "      loss = (recon_loss + kld_loss) * 1.0 / samples.shape[0]\n",
        "      loss.backward()\n",
        "      self.adam.step()\n",
        "\n",
        "      if batch_id % 100 == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_id * samples.shape[0], len(data_loader.dataset),\n",
        "                samples.shape[0] * batch_id / len(data_loader), loss.item() / samples.shape[0]))\n",
        "  \n",
        "  def test_network(self, data_loader, print_prefix='Train', epoch_num=0):\n",
        "\n",
        "    total_loss = 0\n",
        "    total_recon_loss = 0\n",
        "    total_kld_loss = 0\n",
        "    \n",
        "    batch_count = 0\n",
        "    sample_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_id, (samples, labels) in enumerate(data_loader):\n",
        "        samples_flat = samples.view(-1, 784).to(device)\n",
        "        mu, var, decoder_out = self.vae(samples_flat)\n",
        "        recon_loss, kld_loss = loss_function(mu, var, decoder_out, samples_flat)\n",
        "        loss = recon_loss + kld_loss\n",
        "        \n",
        "        total_recon_loss += recon_loss.item()\n",
        "        total_kld_loss += kld_loss.item()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_count += 1\n",
        "        sample_count += samples.shape[0]\n",
        "    \n",
        "    loss_info = np.array([total_recon_loss, total_kld_loss, total_loss])\n",
        "    loss_record = [loss_info, batch_count, sample_count]\n",
        "\n",
        "    print(print_prefix + \" Epoch : {}, Loss: {}, Recon_Loss: {}, KLD_Loss: {}\".format(epoch_num, loss_info[-1]/sample_count, loss_info[0]/sample_count, loss_info[1]/sample_count))\n",
        "    return loss_record\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJwXHWmErojM",
        "colab_type": "text"
      },
      "source": [
        "## VAE Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfyY2CgbrsUL",
        "colab_type": "code",
        "outputId": "74ef2816-a4fd-45a0-b93a-46b531c829a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "vae = VAE()\n",
        "nw = VAEWrapper(vae, 0.001)\n",
        "\n",
        "for  epoch in range(50):\n",
        "  nw.train_network(train_data_loader)\n",
        "  train_loss = nw.test_network(train_data_loader, print_prefix='Train', epoch_num=epoch+1)\n",
        "  test_loss = nw.test_network(test_data_loader, print_prefix='Test', epoch_num=epoch + 1)\n",
        "\n",
        "  nw.train_loss_data.append(train_loss)\n",
        "  nw.test_loss_data.append(test_loss)\n",
        "\n",
        "  test_infer_out = nw.infer_data_from_loader(test_recon_loader)\n",
        "  nw.infer_out.append(test_infer_out)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 5.491292\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 2.038597\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.812299\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.773355\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.773459\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.642642\n",
            "Train Epoch : 1, Loss: 166.0086133951823, Recon_Loss: 149.9522997721354, KLD_Loss: 16.05631377766927\n",
            "Test Epoch : 1, Loss: 165.5425529296875, Recon_Loss: 149.12031796875, KLD_Loss: 16.42223494873047\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.686969\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.649244\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.668156\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.593008\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.673275\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.629853\n",
            "Train Epoch : 2, Loss: 160.9716291829427, Recon_Loss: 141.96920940755209, KLD_Loss: 19.00241982421875\n",
            "Test Epoch : 2, Loss: 160.40404921875, Recon_Loss: 140.84818486328126, KLD_Loss: 19.555864038085936\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.581420\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.658968\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.623903\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.601353\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.733444\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.695246\n",
            "Train Epoch : 3, Loss: 159.39795642903647, Recon_Loss: 140.67561818033855, KLD_Loss: 18.72233819580078\n",
            "Test Epoch : 3, Loss: 158.70056328125, Recon_Loss: 139.49592109375, KLD_Loss: 19.20464317626953\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.590857\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.538090\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.618298\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.567567\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.632066\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.566681\n",
            "Train Epoch : 4, Loss: 158.2855358561198, Recon_Loss: 139.08115659179688, KLD_Loss: 19.204379547119142\n",
            "Test Epoch : 4, Loss: 157.94416123046875, Recon_Loss: 138.2706375, KLD_Loss: 19.673523522949218\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.621716\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.571713\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.614261\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.562926\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.609347\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.660165\n",
            "Train Epoch : 5, Loss: 157.70466349283853, Recon_Loss: 139.00484537760417, KLD_Loss: 18.69981810913086\n",
            "Test Epoch : 5, Loss: 157.07741904296876, Recon_Loss: 137.9214119140625, KLD_Loss: 19.156006811523437\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.595705\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.611681\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.573399\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.569668\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.607167\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.604237\n",
            "Train Epoch : 6, Loss: 157.31329692382812, Recon_Loss: 138.33290981445313, KLD_Loss: 18.980387272135417\n",
            "Test Epoch : 6, Loss: 156.6593111328125, Recon_Loss: 137.28224248046874, KLD_Loss: 19.377069104003905\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.502450\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.666216\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.544364\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.614807\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.584557\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.548073\n",
            "Train Epoch : 7, Loss: 156.75696083984374, Recon_Loss: 136.92218979492188, KLD_Loss: 19.834770827229818\n",
            "Test Epoch : 7, Loss: 156.15458974609376, Recon_Loss: 135.89504208984374, KLD_Loss: 20.259547875976562\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.443456\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.544735\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.582985\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.609397\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.552453\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.522584\n",
            "Train Epoch : 8, Loss: 156.51261160481772, Recon_Loss: 137.10455524088542, KLD_Loss: 19.408056526692707\n",
            "Test Epoch : 8, Loss: 155.80999013671874, Recon_Loss: 135.9429150390625, KLD_Loss: 19.86707517089844\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.573231\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.556118\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.643473\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.627672\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.523102\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.561153\n",
            "Train Epoch : 9, Loss: 156.02632867838543, Recon_Loss: 136.1623841796875, KLD_Loss: 19.86394467976888\n",
            "Test Epoch : 9, Loss: 155.387552734375, Recon_Loss: 135.095119140625, KLD_Loss: 20.292433764648436\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.559853\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.617569\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.555754\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.583851\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.624357\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.619243\n",
            "Train Epoch : 10, Loss: 155.98047848307291, Recon_Loss: 136.83148828125, KLD_Loss: 19.14899026896159\n",
            "Test Epoch : 10, Loss: 155.633203125, Recon_Loss: 136.061825390625, KLD_Loss: 19.571377307128905\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.482159\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.615319\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.574944\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.571515\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.517401\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.630087\n",
            "Train Epoch : 11, Loss: 155.85027338867187, Recon_Loss: 135.5964453125, KLD_Loss: 20.253828092447918\n",
            "Test Epoch : 11, Loss: 155.15627578125, Recon_Loss: 134.47491875, KLD_Loss: 20.681356555175782\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.584621\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.597374\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.579356\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.571536\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.633906\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.603327\n",
            "Train Epoch : 12, Loss: 155.3666400390625, Recon_Loss: 135.8304970703125, KLD_Loss: 19.53614280802409\n",
            "Test Epoch : 12, Loss: 154.84628232421875, Recon_Loss: 134.90129755859374, KLD_Loss: 19.94498428955078\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.628624\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.471152\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.547797\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.504781\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.559406\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.551647\n",
            "Train Epoch : 13, Loss: 155.20164537760417, Recon_Loss: 135.03160218098958, KLD_Loss: 20.17004313151042\n",
            "Test Epoch : 13, Loss: 154.683112109375, Recon_Loss: 134.1039990234375, KLD_Loss: 20.579112646484376\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.556808\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.557116\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.553774\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.491936\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.590929\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.513445\n",
            "Train Epoch : 14, Loss: 155.08006708984374, Recon_Loss: 134.86665543619793, KLD_Loss: 20.213411857096354\n",
            "Test Epoch : 14, Loss: 154.6563509765625, Recon_Loss: 134.04445947265626, KLD_Loss: 20.611891357421875\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.547776\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.544901\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.631816\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.530740\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.529123\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.531096\n",
            "Train Epoch : 15, Loss: 154.82879033203125, Recon_Loss: 134.55085227864583, KLD_Loss: 20.277938061523436\n",
            "Test Epoch : 15, Loss: 154.58228681640625, Recon_Loss: 133.88866240234375, KLD_Loss: 20.69362410888672\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.529945\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.508789\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.546524\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.634003\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.555915\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.537309\n",
            "Train Epoch : 16, Loss: 154.65975799153645, Recon_Loss: 134.5314407877604, KLD_Loss: 20.12831681315104\n",
            "Test Epoch : 16, Loss: 154.1769712890625, Recon_Loss: 133.70018583984375, KLD_Loss: 20.47678537597656\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.583152\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.468996\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.569793\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.586443\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.495669\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.601949\n",
            "Train Epoch : 17, Loss: 154.64529762369793, Recon_Loss: 134.72450802408855, KLD_Loss: 19.9207898050944\n",
            "Test Epoch : 17, Loss: 154.3285443359375, Recon_Loss: 134.02906533203125, KLD_Loss: 20.29947930908203\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.534466\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.597504\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.509800\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.648841\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.559389\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.530882\n",
            "Train Epoch : 18, Loss: 154.35280927734374, Recon_Loss: 134.04290595703125, KLD_Loss: 20.309903228759765\n",
            "Test Epoch : 18, Loss: 154.0145021484375, Recon_Loss: 133.3259107421875, KLD_Loss: 20.688591174316407\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.573134\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.546977\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.551890\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.541515\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.441441\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.573100\n",
            "Train Epoch : 19, Loss: 154.41874104817708, Recon_Loss: 133.72890896809895, KLD_Loss: 20.689832135009766\n",
            "Test Epoch : 19, Loss: 153.97128515625, Recon_Loss: 132.8807984375, KLD_Loss: 21.090486645507813\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.626452\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.541522\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.574375\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.583231\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.594100\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.629346\n",
            "Train Epoch : 20, Loss: 154.3207624674479, Recon_Loss: 134.40198188476563, KLD_Loss: 19.918780682373047\n",
            "Test Epoch : 20, Loss: 153.70810791015626, Recon_Loss: 133.46237177734375, KLD_Loss: 20.245736206054687\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.490629\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.598712\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.527256\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.559863\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.487669\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.542612\n",
            "Train Epoch : 21, Loss: 154.03769611002605, Recon_Loss: 134.00333570963542, KLD_Loss: 20.034360540771484\n",
            "Test Epoch : 21, Loss: 153.7579736328125, Recon_Loss: 133.405796484375, KLD_Loss: 20.352178039550783\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.533282\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.581082\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.525073\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.593176\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.579629\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.603123\n",
            "Train Epoch : 22, Loss: 154.14546520182293, Recon_Loss: 134.33632369791667, KLD_Loss: 19.809141621907553\n",
            "Test Epoch : 22, Loss: 153.6631150390625, Recon_Loss: 133.44679267578124, KLD_Loss: 20.216321667480468\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.508889\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.559956\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.446378\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.551719\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.573454\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.494001\n",
            "Train Epoch : 23, Loss: 153.8989055013021, Recon_Loss: 133.43091245117188, KLD_Loss: 20.467993192545574\n",
            "Test Epoch : 23, Loss: 153.3966265625, Recon_Loss: 132.56409619140624, KLD_Loss: 20.832530041503905\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.624905\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.469254\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.511718\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.571998\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.505358\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.486184\n",
            "Train Epoch : 24, Loss: 153.9265591796875, Recon_Loss: 133.623143359375, KLD_Loss: 20.303416056315104\n",
            "Test Epoch : 24, Loss: 153.6312673828125, Recon_Loss: 133.00063828125, KLD_Loss: 20.630629345703124\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.540949\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.563583\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.438866\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.584501\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.513042\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.560419\n",
            "Train Epoch : 25, Loss: 154.00662928059896, Recon_Loss: 132.91557180989582, KLD_Loss: 21.091057495117187\n",
            "Test Epoch : 25, Loss: 153.233719921875, Recon_Loss: 131.77516875, KLD_Loss: 21.45855137939453\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.597578\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.563863\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.562614\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.556652\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.505387\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.449838\n",
            "Train Epoch : 26, Loss: 153.98607880859376, Recon_Loss: 133.3668846028646, KLD_Loss: 20.61919408569336\n",
            "Test Epoch : 26, Loss: 153.3349044921875, Recon_Loss: 132.3911892578125, KLD_Loss: 20.943714721679687\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.467791\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.535191\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.471794\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.498119\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.582108\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.536077\n",
            "Train Epoch : 27, Loss: 153.97437493489582, Recon_Loss: 133.1921957845052, KLD_Loss: 20.782179154459634\n",
            "Test Epoch : 27, Loss: 153.4076599609375, Recon_Loss: 132.26470126953126, KLD_Loss: 21.142958642578126\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.524093\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.613378\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.556757\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.507321\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.652193\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.507055\n",
            "Train Epoch : 28, Loss: 153.4533940266927, Recon_Loss: 133.38360349934896, KLD_Loss: 20.06979072265625\n",
            "Test Epoch : 28, Loss: 153.01757568359375, Recon_Loss: 132.60039072265624, KLD_Loss: 20.417184936523437\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.533773\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.525301\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.537296\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.591917\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.527673\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.470162\n",
            "Train Epoch : 29, Loss: 153.65505771484376, Recon_Loss: 133.81496393229168, KLD_Loss: 19.840093815104165\n",
            "Test Epoch : 29, Loss: 153.4959501953125, Recon_Loss: 133.35212119140624, KLD_Loss: 20.143829296875\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.542365\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.492698\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.504321\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.497527\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.569418\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.501459\n",
            "Train Epoch : 30, Loss: 153.66463168945313, Recon_Loss: 132.50417682291666, KLD_Loss: 21.16045474650065\n",
            "Test Epoch : 30, Loss: 153.3772318359375, Recon_Loss: 131.850965234375, KLD_Loss: 21.526266723632812\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.548987\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.558658\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.541833\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.592783\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.539447\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.565098\n",
            "Train Epoch : 31, Loss: 153.4860671875, Recon_Loss: 132.4861413736979, KLD_Loss: 20.99992573445638\n",
            "Test Epoch : 31, Loss: 153.21078623046876, Recon_Loss: 131.9030392578125, KLD_Loss: 21.307746838378907\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.521665\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.469658\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.538292\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.468894\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.537294\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.505836\n",
            "Train Epoch : 32, Loss: 153.39288430989583, Recon_Loss: 132.98860131835937, KLD_Loss: 20.40428304239909\n",
            "Test Epoch : 32, Loss: 153.13241806640625, Recon_Loss: 132.44106728515624, KLD_Loss: 20.691350756835938\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.508662\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.512636\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.528884\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.536249\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.560424\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.487760\n",
            "Train Epoch : 33, Loss: 153.7621244140625, Recon_Loss: 133.320690625, KLD_Loss: 20.441433799235025\n",
            "Test Epoch : 33, Loss: 153.62944658203125, Recon_Loss: 132.86121796875, KLD_Loss: 20.768228649902344\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.467175\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.573878\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.508842\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.568636\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.548414\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.557336\n",
            "Train Epoch : 34, Loss: 153.41366875, Recon_Loss: 132.47292473958333, KLD_Loss: 20.940744150797524\n",
            "Test Epoch : 34, Loss: 153.09961591796875, Recon_Loss: 131.80700390625, KLD_Loss: 21.292612036132812\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.525911\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.633071\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.558878\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.561882\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.608929\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.575345\n",
            "Train Epoch : 35, Loss: 153.70034235026043, Recon_Loss: 132.89650818684896, KLD_Loss: 20.803834147135415\n",
            "Test Epoch : 35, Loss: 153.4054595703125, Recon_Loss: 132.2715263671875, KLD_Loss: 21.133933044433594\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.566219\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.502641\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.535847\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.526909\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.490096\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.487932\n",
            "Train Epoch : 36, Loss: 153.25251168619792, Recon_Loss: 132.59861121419272, KLD_Loss: 20.653900563557944\n",
            "Test Epoch : 36, Loss: 152.6771666015625, Recon_Loss: 131.6982033203125, KLD_Loss: 20.978963220214844\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.529752\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.575687\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.529783\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.426675\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.517764\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.523649\n",
            "Train Epoch : 37, Loss: 153.31825167643228, Recon_Loss: 132.30131087239585, KLD_Loss: 21.016940856933594\n",
            "Test Epoch : 37, Loss: 152.61456201171876, Recon_Loss: 131.351729296875, KLD_Loss: 21.26283259277344\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.559756\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.523034\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.547715\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.496224\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.587972\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.523585\n",
            "Train Epoch : 38, Loss: 153.1228317220052, Recon_Loss: 132.6853626627604, KLD_Loss: 20.43746918334961\n",
            "Test Epoch : 38, Loss: 153.0315208984375, Recon_Loss: 132.32731181640625, KLD_Loss: 20.704209313964842\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.513868\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.498391\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.413279\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.535385\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.545914\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.526276\n",
            "Train Epoch : 39, Loss: 153.2610026204427, Recon_Loss: 133.00121472981772, KLD_Loss: 20.259787813313803\n",
            "Test Epoch : 39, Loss: 152.9099568359375, Recon_Loss: 132.3925048828125, KLD_Loss: 20.517452111816407\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.505939\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.558506\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.585961\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.479316\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.557741\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.558914\n",
            "Train Epoch : 40, Loss: 153.15563515625, Recon_Loss: 132.6072505045573, KLD_Loss: 20.548384729003907\n",
            "Test Epoch : 40, Loss: 152.81252880859375, Recon_Loss: 132.0283697265625, KLD_Loss: 20.784159020996093\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.499312\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.526690\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.567674\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.495927\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.485804\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.475348\n",
            "Train Epoch : 41, Loss: 153.06592998046875, Recon_Loss: 132.7309285970052, KLD_Loss: 20.335001513671877\n",
            "Test Epoch : 41, Loss: 153.195932421875, Recon_Loss: 132.54858056640626, KLD_Loss: 20.647351928710936\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.619013\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.537144\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.539195\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.544752\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.691910\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.584792\n",
            "Train Epoch : 42, Loss: 152.9796109375, Recon_Loss: 132.24181619466145, KLD_Loss: 20.73779455973307\n",
            "Test Epoch : 42, Loss: 152.5615828125, Recon_Loss: 131.5403271484375, KLD_Loss: 21.021256079101562\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.439297\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.531530\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.537173\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.559655\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.486904\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.506385\n",
            "Train Epoch : 43, Loss: 152.93064583333333, Recon_Loss: 132.15872552083334, KLD_Loss: 20.771920487467447\n",
            "Test Epoch : 43, Loss: 152.30174482421876, Recon_Loss: 131.270173828125, KLD_Loss: 21.031571020507812\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.469675\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.490316\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.526771\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.536211\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.546712\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.555400\n",
            "Train Epoch : 44, Loss: 152.85330083007813, Recon_Loss: 132.49011591796875, KLD_Loss: 20.363184733072917\n",
            "Test Epoch : 44, Loss: 152.604346484375, Recon_Loss: 131.9310671875, KLD_Loss: 20.673279431152345\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.570901\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.558087\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.535555\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.561372\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.441335\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.539140\n",
            "Train Epoch : 45, Loss: 153.1344727376302, Recon_Loss: 131.8165311686198, KLD_Loss: 21.317941571044923\n",
            "Test Epoch : 45, Loss: 152.91609697265625, Recon_Loss: 131.34130302734374, KLD_Loss: 21.574793615722655\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.641713\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.433385\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.519940\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.516622\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.463762\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.472840\n",
            "Train Epoch : 46, Loss: 152.88287361653647, Recon_Loss: 131.93576031901043, KLD_Loss: 20.9471135538737\n",
            "Test Epoch : 46, Loss: 152.267310546875, Recon_Loss: 131.01438896484376, KLD_Loss: 21.252921350097655\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.553700\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.560429\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.560037\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.545285\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.532036\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.557213\n",
            "Train Epoch : 47, Loss: 152.99454770507813, Recon_Loss: 132.57782970377605, KLD_Loss: 20.416718013509115\n",
            "Test Epoch : 47, Loss: 152.55918017578125, Recon_Loss: 131.9201671875, KLD_Loss: 20.639012902832032\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.557128\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.487349\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.629321\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.484911\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.574652\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.522696\n",
            "Train Epoch : 48, Loss: 152.73792875976562, Recon_Loss: 132.01754951171876, KLD_Loss: 20.720379374186198\n",
            "Test Epoch : 48, Loss: 152.243398828125, Recon_Loss: 131.267403125, KLD_Loss: 20.975995166015625\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.524058\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.564483\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.534060\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.550706\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.545068\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.482622\n",
            "Train Epoch : 49, Loss: 153.06824892578126, Recon_Loss: 132.27401349283855, KLD_Loss: 20.79423550008138\n",
            "Test Epoch : 49, Loss: 152.7469408203125, Recon_Loss: 131.68728955078126, KLD_Loss: 21.059651428222658\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.419329\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 1.524646\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 1.487767\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 1.566089\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 1.458543\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 1.440365\n",
            "Train Epoch : 50, Loss: 152.71663391927083, Recon_Loss: 132.1900352376302, KLD_Loss: 20.526598795572916\n",
            "Test Epoch : 50, Loss: 152.44703701171875, Recon_Loss: 131.7181076171875, KLD_Loss: 20.72892911376953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5df0Zrfrs0J",
        "colab_type": "text"
      },
      "source": [
        "## VAE Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJFN-9RzY45U",
        "colab_type": "code",
        "outputId": "dba58be2-62c4-4663-bf7c-a1ef269051bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# nw = VAEWrapper(vae, 0.001)\n",
        "\n",
        "# nw.infer_data(test_dataset[10][0])\n",
        "from matplotlib import gridspec\n",
        "\n",
        "def plot_grid(data, index_list, sample_size):\n",
        "  # f, axarr = plt.subplots(sample_size, len(index_list))\n",
        "  gs = gridspec.GridSpec(sample_size, len(index_list), width_ratios=[1 for k in range(len(index_list))],\n",
        "         wspace=0.1, hspace=0.1) \n",
        "\n",
        "  for i, index in enumerate(index_list):\n",
        "    sample = data[index][0][:sample_size, :, :]\n",
        "    for s_index in range(sample_size):\n",
        "      #axarr[s_index, i].imshow(sample[s_index, :, :])\n",
        "      plt.subplot(gs[s_index, i]).imshow(sample[s_index, :, :])\n",
        "      plt.subplot(gs[s_index, i]).axis('off')\n",
        "  \n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_grid(nw.infer_out, [1,5,15, 20, 25, 30], 6)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAADnCAYAAACXHnS/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 36 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFIk-avEZag5",
        "colab_type": "text"
      },
      "source": [
        "# 2.2 DCGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOdYk0hTZetS",
        "colab_type": "text"
      },
      "source": [
        "# 3 CIS GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXG3cT9LaJlg",
        "colab_type": "text"
      },
      "source": [
        "## Data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0SoMZMbaJRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CISDataset():\n",
        "  def __init__(self, input_path):\n",
        "    load_data = np.load(input_path)\n",
        "    self.data = load_data['arr_0'] / 255.0\n",
        "    self.length = self.data.shape[0]\n",
        "    del load_data\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.length \n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index, :, :, :]\n",
        "    down_sample_image = resize(image, (16, 16))\n",
        "    up_sample_image = resize(down_sample_image, (64, 64))\n",
        "    trans_image, trans_blur = np.moveaxis(image, -1, 0), np.moveaxis(up_sample_image, -1, 0)\n",
        "    return trans_image, trans_blur\n",
        "\n",
        "def custom_collate(batch):\n",
        "  return default_collate(batch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQkZYLllcwQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cis_train_data_set = CISDataset('train.npz')\n",
        "cis_test_data_set = CISDataset('test.npz')\n",
        "\n",
        "cis_train_data_loader = DataLoader(cis_train_data_set, collate_fn=custom_collate, batch_size=10, shuffle=True)\n",
        "cis_test_data_loader = DataLoader(cis_test_data_set, collate_fn=custom_collate, batch_size=10, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-Z_nmDOdDsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image, blur = cis_train_data_set[8]\n",
        "\n",
        "plt.imshow(np.moveaxis(image, 0, -1))\n",
        "plt.show()\n",
        "plt.imshow(np.moveaxis(blur, 0, -1))\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI4ZRjmGfLY4",
        "colab_type": "text"
      },
      "source": [
        "## CIS Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uf4o2bqfIlA",
        "colab_type": "code",
        "outputId": "7c9e8e2a-6948-4278-e81d-55d7506b17f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class CISEncoder(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Sequential(nn.Conv2d(3, 32, 4, stride=2, padding=1), nn.BatchNorm2d(32), nn.LeakyReLU())\n",
        "    self.layer2 = nn.Sequential(nn.Conv2d(32, 64, 4, stride=2, padding=1), nn.BatchNorm2d(64), nn.LeakyReLU())\n",
        "    self.layer3 = nn.Sequential(nn.Conv2d(64, 128, 4, stride=2, padding=1), nn.BatchNorm2d(128), nn.LeakyReLU())\n",
        "    self.layer4 = nn.Sequential(nn.Conv2d(128, 256, 4, stride=2, padding=1), nn.BatchNorm2d(256), nn.LeakyReLU())\n",
        "    self.layer5 = nn.Sequential(nn.Conv2d(256, 512, 4, stride=2, padding=1), nn.BatchNorm2d(512), nn.LeakyReLU())\n",
        "  \n",
        "  def forward(self, X):\n",
        "    l1_out = self.layer1(X)\n",
        "    l2_out = self.layer2(l1_out)\n",
        "    l3_out = self.layer3(l2_out)\n",
        "    l4_out = self.layer4(l3_out)\n",
        "    l5_out = self.layer5(l4_out)\n",
        "    return (l1_out, l2_out, l3_out, l4_out, l5_out)\n",
        "\n",
        "class CISDecoder(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Sequential(nn.ConvTranspose2d(512 + 512, 256, kernel_size=4, stride=2, padding=1), nn.BatchNorm2d(256), nn.LeakyReLU())\n",
        "    self.layer2 = nn.Sequential(nn.ConvTranspose2d(256 + 256, 128, kernel_size=4, stride=2, padding=1), nn.BatchNorm2d(128), nn.LeakyReLU())\n",
        "    self.layer3 = nn.Sequential(nn.ConvTranspose2d(128+128, 64, kernel_size=4, stride=2, padding=1), nn.BatchNorm2d(64), nn.LeakyReLU())\n",
        "    self.layer4 = nn.Sequential(nn.ConvTranspose2d(64+64, 32, kernel_size=4, stride=2, padding=1), nn.BatchNorm2d(32), nn.LeakyReLU())\n",
        "    self.layer5 = nn.Sequential(nn.ConvTranspose2d(32+32, 16, kernel_size=4, stride=2, padding=1), nn.BatchNorm2d(16), nn.LeakyReLU())\n",
        "    self.layer6 = nn.Sequential(nn.ConvTranspose2d(16+3, 3, kernel_size=3, padding=1), nn.Tanh())\n",
        "\n",
        "  def forward(self, encoder_out, inp_x, inp_z):\n",
        "    l1_out = self.layer1(torch.cat([inp_z,  encoder_out[4]], dim=1))\n",
        "    l2_out = self.layer2(torch.cat([l1_out, encoder_out[3]], dim=1))\n",
        "    l3_out = self.layer3(torch.cat([l2_out, encoder_out[2]], dim=1))\n",
        "    l4_out = self.layer4(torch.cat([l3_out, encoder_out[1]], dim=1))\n",
        "    l5_out = self.layer5(torch.cat([l4_out, encoder_out[0]], dim=1))\n",
        "    l6_out = self.layer6(torch.cat([l5_out, inp_x], dim=1))\n",
        "\n",
        "    return l6_out\n",
        "\n",
        "class CISGenerator(torch.nn.Module):\n",
        "  def __init__(self, ce, cd):\n",
        "    super().__init__()\n",
        "    self.ce = ce\n",
        "    self.cd = cd\n",
        "  \n",
        "  def forward(self, inp_x, inp_z):\n",
        "    ot = self.ce(inp_x)\n",
        "    od = self.cd(ot, inp_x, inp_z)\n",
        "    return od\n",
        "\n",
        "class CISDisc(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Sequential(nn.Conv2d(3, 32, 4, stride=2, padding=1), nn.BatchNorm2d(32), nn.LeakyReLU())\n",
        "    self.layer2 = nn.Sequential(nn.Conv2d(32, 64, 4, stride=2, padding=1), nn.BatchNorm2d(64), nn.LeakyReLU())\n",
        "    self.layer3 = nn.Sequential(nn.Conv2d(64, 128, 4, stride=2, padding=1), nn.BatchNorm2d(128), nn.LeakyReLU())\n",
        "    self.layer4 = nn.Sequential(nn.Conv2d(128, 256, 4, stride=2, padding=1), nn.BatchNorm2d(256), nn.LeakyReLU())\n",
        "    self.layer5 = nn.Sequential(nn.Conv2d(256, 512, 4, stride=2, padding=1), nn.BatchNorm2d(512), nn.LeakyReLU())\n",
        "    self.layer6 = nn.Sequential(nn.Conv2d(512, 1, 3, stride=2, padding=1), nn.Sigmoid())\n",
        "  \n",
        "  def forward(self, X):\n",
        "    l1_out = self.layer1(X)\n",
        "    l2_out = self.layer2(l1_out)\n",
        "    l3_out = self.layer3(l2_out)\n",
        "    l4_out = self.layer4(l3_out)\n",
        "    l5_out = self.layer5(l4_out)\n",
        "    l6_out = self.layer6(l5_out)\n",
        "\n",
        "    return l6_out \n",
        "\n",
        "\n",
        "ce = CISEncoder().to(device)\n",
        "cd = CISDecoder().to(device)\n",
        "\n",
        "cgen = CISGenerator(ce, cd).to(device)\n",
        "cdisc = CISDisc().to(device)\n",
        "\n",
        "inp_x = torch.zeros((10, 3, 64, 64)).type(torch.float).to(device)\n",
        "inp_z = torch.zeros((10, 512, 2, 2)).type(torch.float).to(device)\n",
        "\n",
        "opt = cgen(inp_x, inp_z)\n",
        "out = cdisc(opt)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQA90BuVocXf",
        "colab_type": "text"
      },
      "source": [
        "## CIS Model Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1WGJEBmocBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REAL_LABEL = 1.0\n",
        "FAKE_LABEL = 0.0\n",
        "\n",
        "class CISModelWrapper():\n",
        "  def __init__(self, cgen, cdisc, lr_gen, lr_disc):\n",
        "    self.cgen = cgen\n",
        "    self.cdisc = cdisc\n",
        "    self.optimizerG = torch.optim.Adam(self.cgen.parameters(), lr=lr_gen)\n",
        "    self.optimizerD = torch.optim.Adam(self.cdisc.parameters(), lr=lr_disc)\n",
        "  \n",
        "  def train_samples_disc(self, samples, noise):\n",
        "      \n",
        "    self.cdisc.zero_grad()\n",
        "    noise = noise.to(device)\n",
        "\n",
        "    batch_size = samples.shape[0]  \n",
        "    real_samples = samples.to(device)\n",
        "    real_labels = torch.full((batch_size,), REAL_LABEL, device=device)\n",
        "      \n",
        "    real_output = self.cdisc(real_samples).view(-1)\n",
        "    real_loss = F.binary_cross_entropy(real_output, real_labels)\n",
        "    real_loss.backward()\n",
        "\n",
        "    fake_samples = self.cgen(real_samples, noise)\n",
        "    fake_labels = torch.full((batch_size,), FAKE_LABEL, device=device)\n",
        "\n",
        "    fake_out = self.cdisc(fake_samples.detach()).view(-1)\n",
        "    fake_loss = F.binary_cross_entropy(fake_out, fake_labels)\n",
        "    fake_loss.backward()\n",
        "\n",
        "    total_loss = real_loss + fake_loss\n",
        "    self.optimizerD.step()\n",
        "  \n",
        "  def train_samples_gen(self, samples, noise):\n",
        "\n",
        "    self.cgen.zero_grad()\n",
        "\n",
        "    batch_size = samples.shape[0]\n",
        "    samples = samples.to(device)\n",
        "\n",
        "    gen_out = self.cgen(samples, noise)\n",
        "    labels = torch.full((batch_size,), REAL_LABEL, device=device)\n",
        "\n",
        "    mse_loss = F.mse_loss(gen_out, samples)\n",
        "\n",
        "    disc_out = self.cdisc(gen_out).view(-1)\n",
        "    cls_loss = F.binary_cross_entropy(disc_out, labels)\n",
        "\n",
        "    total_loss = mse_loss + cls_loss\n",
        "\n",
        "    total_loss.backward()\n",
        "    self.optimizerG.step()\n",
        "  \n",
        "  def train_cis(self, data_loader):\n",
        "\n",
        "    for batch_id, samples in enumerate(data_loader):\n",
        "      batch_size = samples.shape[0]\n",
        "      noise = torch.randn(batch_size, 512, 2, 2, device=device)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvNh3B3FiAPY",
        "colab_type": "text"
      },
      "source": [
        "# Train your networks\n",
        "\n",
        "It might be good to save checkpoints and reload from the most recent. This is due to time constraints inside of colab. (Probably a good idea to train each part in separate blocks?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQuOI_n_iEiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSyobxVWqBMA",
        "colab_type": "text"
      },
      "source": [
        "# Test your networks\n",
        "\n",
        "Did you remember to cut out a test set? If not you really should, test on images your network has never seen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c0SdpUjqJ88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}